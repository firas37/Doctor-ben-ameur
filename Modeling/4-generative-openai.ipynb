{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Imports\n",
    "import os\n",
    "import json  # Ajout de l'import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.api.types import EmbeddingFunction\n",
    "from sklearn.model_selection import train_test_split\n",
    "import openai\n",
    "import time  # Pour le délai entre les appels API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Charger la clé OpenAI\n",
    "with open('./credentials/api.json') as f:\n",
    "    data = json.load(f)\n",
    "    OPENAI_API_KEY = data['OPENAI_API_KEY']\n",
    "    openai.api_key = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (950, 6)\n",
      "Test shape: (50, 6)\n"
     ]
    }
   ],
   "source": [
    "filename_data = '../datacreation/dialogues_embededd.pkl'\n",
    "data = pd.read_pickle(filename_data)\n",
    "train_data, test_data = train_test_split(data, test_size=0.05)\n",
    "print(\"Train shape:\", train_data.shape)\n",
    "print(\"Test shape:\", test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Question  \\\n",
      "0        Will masturbation cause weakness in nerves?   \n",
      "1  Could lack of hair growth be due to masturbation?   \n",
      "\n",
      "                                             Patient  \\\n",
      "0  Hi, may I answer your health queries right now...   \n",
      "1  hai sir i am 25years old i used to do masturba...   \n",
      "\n",
      "                                              Answer  \\\n",
      "0  Hi, Masturbation does make the nerves weak whe...   \n",
      "1  Hi, Since you said you masturbate frequently e...   \n",
      "\n",
      "                                            combined  ids  \n",
      "0  Question: Will masturbation cause weakness in ...    0  \n",
      "1  Question: Could lack of hair growth be due to ...    1  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../datacreation/dialogues.csv', sep='\\t')\n",
    "df = df.dropna()\n",
    "df.rename(columns={'Description':'Question', 'Doctor':'Answer'}, inplace=True)\n",
    "df['combined'] = 'Question: ' + df.Question.str.strip() + '\\nAnswer: ' + df.Answer.str.strip()\n",
    "df = df.drop_duplicates().reset_index(drop=True)\n",
    "df['ids'] = df.index\n",
    "documents = df\n",
    "print(documents.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\firas\\AppData\\Local\\Temp\\ipykernel_23240\\1187675410.py:5: DeprecationWarning: The class MiniLML6V2EmbeddingFunction does not implement __init__. This will be required in a future version.\n",
      "  emb_func = MiniLML6V2EmbeddingFunction()\n"
     ]
    }
   ],
   "source": [
    "class MiniLML6V2EmbeddingFunction(EmbeddingFunction):\n",
    "    MODEL = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    def __call__(self, texts):\n",
    "        return MiniLML6V2EmbeddingFunction.MODEL.encode(texts).tolist()\n",
    "emb_func = MiniLML6V2EmbeddingFunction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChromaWithUpsert:\n",
    "    def __init__(\n",
    "            self,\n",
    "            name='openai_rag_collection',\n",
    "            persist_directory=None,\n",
    "            embedding_function=None,\n",
    "            collection_metadata=None,\n",
    "    ):\n",
    "        if persist_directory is not None:\n",
    "            self._client = chromadb.PersistentClient(path=persist_directory)\n",
    "        else:\n",
    "            self._client = chromadb.EphemeralClient()\n",
    "        self._embedding_function = embedding_function\n",
    "        self._persist_directory = persist_directory\n",
    "        self._name = name\n",
    "        self._collection = self._client.get_or_create_collection(\n",
    "            name=self._name,\n",
    "            embedding_function=self._embedding_function\n",
    "            if self._embedding_function is not None\n",
    "            else None,\n",
    "            metadata=collection_metadata,\n",
    "        )\n",
    "\n",
    "    def upsert_texts(\n",
    "        self,\n",
    "        texts,\n",
    "        metadata=None,\n",
    "        ids=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        texts_list = list(texts)\n",
    "        if ids is None:\n",
    "            import uuid\n",
    "            ids = [str(uuid.uuid1()) for _ in texts_list]\n",
    "        batch_size = 5000\n",
    "        for i in range(0, len(texts_list), batch_size):\n",
    "            end = min(i + batch_size, len(texts_list))\n",
    "            batch_texts = texts_list[i:end]\n",
    "            batch_ids = ids[i:end]\n",
    "            batch_metadata = None if metadata is None else metadata[i:end]\n",
    "            self._collection.upsert(\n",
    "                metadatas=batch_metadata, \n",
    "                documents=batch_texts, \n",
    "                ids=batch_ids\n",
    "            )\n",
    "        return ids\n",
    "\n",
    "    def is_empty(self):\n",
    "        return self._collection.count() == 0\n",
    "\n",
    "    def persist(self):\n",
    "        if hasattr(self._client, 'persist'):\n",
    "            self._client.persist()\n",
    "\n",
    "    def query(self, query_texts, n_results=5):\n",
    "        return self._collection.query(query_texts=query_texts, n_results=n_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La base de connaissances est déjà indexée.\n"
     ]
    }
   ],
   "source": [
    "knowledge_base_dir = '../datacreation/knowledge_base_openai'\n",
    "os.makedirs(knowledge_base_dir, exist_ok=True)\n",
    "\n",
    "chroma = ChromaWithUpsert(\n",
    "    name='openai_rag_collection',\n",
    "    embedding_function=emb_func,\n",
    "    persist_directory=knowledge_base_dir,\n",
    ")\n",
    "\n",
    "if chroma.is_empty():\n",
    "    batch_size = 100\n",
    "    texts = documents.combined.tolist()\n",
    "    metadata = [{'Question': q, 'ids': i} for q, i in zip(documents.Question, documents.ids)]\n",
    "    ids = [str(i) for i in documents.ids]\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        end = min(i + batch_size, len(texts))\n",
    "        batch_texts = texts[i:end]\n",
    "        batch_metadata = metadata[i:end]\n",
    "        batch_ids = ids[i:end]\n",
    "        _ = chroma.upsert_texts(\n",
    "            texts=batch_texts,\n",
    "            metadata=batch_metadata,\n",
    "            ids=batch_ids\n",
    "        )\n",
    "        chroma.persist()\n",
    "    print(\"Indexation terminée !\")\n",
    "else:\n",
    "    print(\"La base de connaissances est déjà indexée.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the treatment for premature ejaculation?\n",
      "What causes premature ejaculation?\n",
      "What causes relapse of chronic bacterial prostatitis?\n",
      "What causes pain in penis?\n",
      "Suggest treatment for swelling in scrotum and hematospermia?\n"
     ]
    }
   ],
   "source": [
    "question_texts = [q.strip(\"?\") + \"?\" for q in test_data['Question'].tolist()]\n",
    "print(\"\\n\".join(question_texts[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_contexts = []\n",
    "for question_text in question_texts:\n",
    "    relevant_chunks = chroma.query(\n",
    "        query_texts=[question_text],\n",
    "        n_results=5,\n",
    "    )\n",
    "    relevant_contexts.append(relevant_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Veuillez répondre à la question suivante en vous appuyant sur le contexte fourni.\n",
      "Question: Suggest treatment for premature ejaculation\n",
      "Answer: Hi, This is a very common problem and unfortunately, there’s no medication for the same. The commonest cause of premature ejaculation is the anxiety of performance. A behavioural technique such as squeeze-pause technique, desensitizing creams and SRRI (selective serotonin reuptake inhibitors) are few common treatments useful in premature ejaculation. You should take consultation with a sex therapist, psychologist, or psychiatrist to be assessed properly. Hope I have answered your query. Let me know if I can assist you further. Take care Regards, Dr. Iven Romic Rommstein\n",
      "\n",
      "Question: What is the treatment for premature ejaculation?\n",
      "Answer: Hi,Premature ejaculation is mainly treated with psychotherapy and proper training.  If you are new to sex then it will automatically improve with time. In the resistant cases selective serotonin replace inhibitor  is usually used. Hope it helps. If you have any other question please do not hesitate to contact us.Regards,Dr. Atishay Bukharia\n",
      "\n",
      "Question: Suggest treatment for premature ejaculation\n",
      "Answer: Hello, Please let us know your age please. Premature ejaculation is mostly psychological unless your have certain health conditions like diabetics, hypertension, thyroid problems etc. Therefore I suggest consulting an urologist for physical examination, diagnosis and treatment. Hope I have answered your query. Let me know if I can assist you further. Take care Regards, Dr. K. V. Anand\n",
      "\n",
      "Question: Suggest treatment for premature ejaculation\n",
      "Answer: Hi, It is called pre-ejaculatory fluid. It is common in a person who has a lot of sexual urge and no sexual contact. It can be prevented by decreasing sex urge by - regular exercise and yoga. Having regular sex can also prevent this issue. Hope I have answered your query. Let me know if I can assist you further. Regards, Dr. S. R. Raveendran, Sexologist\n",
      "\n",
      "Question: Suggest treatment for premature ejacuation\n",
      "Answer: Hello. I have reviewed your query and here is my advice. The given problem of premature ejaculation is mainly due to psychological reasons. Get yourself checked for diabetes and high blood pressure.Hope I have answered your query. You can contact me for treatment options. Let me know if I can assist you further. Regards, Dr. K. V. Anand\n",
      "\n",
      "Question : What is the treatment for premature ejaculation?\n"
     ]
    }
   ],
   "source": [
    "def make_prompt(context, question_text):\n",
    "    return (f\"Veuillez répondre à la question suivante en vous appuyant sur le contexte fourni.\\n\"\n",
    "            f\"{context}\\n\\n\"\n",
    "            f\"Question : {question_text}\")\n",
    "\n",
    "prompt_texts = []\n",
    "for relevant_context, question_text in zip(relevant_contexts, question_texts):\n",
    "    context = \"\\n\\n\".join(relevant_context[\"documents\"][0])\n",
    "    prompt_text = make_prompt(context, question_text)\n",
    "    prompt_texts.append(prompt_text)\n",
    "\n",
    "print(prompt_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur OpenAI: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Erreur OpenAI: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Erreur OpenAI: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Erreur OpenAI: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Erreur OpenAI: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Erreur OpenAI: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Erreur OpenAI: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Erreur OpenAI: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Erreur OpenAI: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Erreur OpenAI: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    }
   ],
   "source": [
    "def generate_openai_answer(prompt, model=\"gpt-3.5-turbo\", temperature=0.2):\n",
    "       response = openai.chat.completions.create(\n",
    "           model=model,\n",
    "           messages=[\n",
    "               {\"role\": \"system\", \"content\": \"Vous êtes un assistant médical compétent.\"},\n",
    "               {\"role\": \"user\", \"content\": prompt}\n",
    "           ],\n",
    "           temperature=temperature,\n",
    "           max_tokens=512\n",
    "       )\n",
    "       return response.choices[0].message.content\n",
    "\n",
    "results = []\n",
    "for prompt_text in prompt_texts[:10]:  # Limitez à 10 pour tester, puis élargissez\n",
    "    try:\n",
    "        answer = generate_openai_answer(prompt_text)\n",
    "        results.append(answer)\n",
    "        time.sleep(1)  # Pour éviter de dépasser le quota API\n",
    "    except Exception as e:\n",
    "        print(\"Erreur OpenAI:\", e)\n",
    "        results.append(\"Erreur API\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur OpenAI: \n",
      "\n",
      "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
      "\n",
      "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
      "\n",
      "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
      "\n",
      "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
      "\n",
      "Erreur OpenAI: \n",
      "\n",
      "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
      "\n",
      "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
      "\n",
      "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
      "\n",
      "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
      "\n",
      "Erreur OpenAI: \n",
      "\n",
      "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
      "\n",
      "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
      "\n",
      "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
      "\n",
      "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
      "\n",
      "Erreur OpenAI: \n",
      "\n",
      "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
      "\n",
      "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
      "\n",
      "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
      "\n",
      "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
      "\n",
      "Erreur OpenAI: \n",
      "\n",
      "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
      "\n",
      "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
      "\n",
      "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
      "\n",
      "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
      "\n",
      "Erreur OpenAI: \n",
      "\n",
      "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
      "\n",
      "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
      "\n",
      "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
      "\n",
      "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
      "\n",
      "Erreur OpenAI: \n",
      "\n",
      "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
      "\n",
      "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
      "\n",
      "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
      "\n",
      "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
      "\n",
      "Erreur OpenAI: \n",
      "\n",
      "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
      "\n",
      "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
      "\n",
      "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
      "\n",
      "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
      "\n",
      "Erreur OpenAI: \n",
      "\n",
      "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
      "\n",
      "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
      "\n",
      "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
      "\n",
      "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
      "\n",
      "Erreur OpenAI: \n",
      "\n",
      "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
      "\n",
      "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
      "\n",
      "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
      "\n",
      "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_openai_answer(prompt, model=\"gpt-3.5-turbo\", temperature=0.2):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Vous êtes un assistant médical compétent.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=temperature,\n",
    "        max_tokens=512\n",
    "    )\n",
    "    return response['choices'][0]['message']['content']\n",
    "\n",
    "results = []\n",
    "for prompt_text in prompt_texts[:10]:  # Limitez à 10 pour tester, puis élargissez\n",
    "    try:\n",
    "        answer = generate_openai_answer(prompt_text)\n",
    "        results.append(answer)\n",
    "        time.sleep(1)  # Pour éviter de dépasser le quota API\n",
    "    except Exception as e:\n",
    "        print(\"Erreur OpenAI:\", e)\n",
    "        results.append(\"Erreur API\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
